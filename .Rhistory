install.packages("likelihoodR")
install.packages("Rtools")
library(likelihoodR)
mysample <- c(0.7, -1.6, -0.2, -1.2, -0.1, 3.4, 3.7, 0.8, 0.0, 2.0)
w=L_ttest(mysample, null=0, d=0.5, alt.2=1, L.int=2, verb = TRUE)
w=L_ttest(mysample, d=0.5, alt.2=1, L.int=2)
w=L_ttest(mysample, d=0.5, alt.2=2, L.int=2)
w
a1=L_ttest(mysample, d=0.5, alt.2=2, L.int=2)
a1
mat.samps <- function(n, nsim = 10000, rx = rnorm, ...) {
samps <- rx(n*nsim, ...)
matrix(sample(samps), nrow=nsim, ncol = n)
}
cond.mean <- function(x,y) {
for (i in unique(y)) {
print(mean(x[y==i]))
}}
cond.mean(x = iris$Sepal.Width,y = iris$Species)
cond.mean <- function(x,y) {
for (i in unique(y)) {
print(mean(x[y==i]))
}
}
cond.mean(x = iris$Sepal.Width,y = iris$Species)
s.mat <- mat.samps(n = 25, nsim = 10000)
HelloWorld <- function(...) {
arguments <- list(...)
paste(arguments)
}
HelloWorld("Hello", "World", "!")
s.mat
mat.samps <- function(n, nsim = 10000, rx = rnorm, ...) {
samps <- rx(n, nsim, ...)
matrix(sample(samps), nrow=nsim, ncol = n)
}
s.mat <- mat.samps(n = 25, nsim = 10000)
s.mat
d <- rnorm(25,0,1)
d
mean(d)
ests.mean <- numeric(10000)
for (i in 1:10000) {
ests.mean[i] <- mean(s.mat[i,])
}
ests.mean
mat.samps <- function(n, nsim = 10000, rx = rnorm, ...) {
samps <- rx(n*nsim, ...)
matrix(sample(samps), nrow=nsim, ncol = n)
}
s.mat <- mat.samps(n = 25, nsim = 10000)
ests.mean <- numeric(10000)
for (i in 1:10000) {
ests.mean[i] <- mean(s.mat[i,])
}
ests.mean
ests.mean <- apply(s.mat, 1, mean)
for (i in 1:10000) {
ests.mean[i] <- mean(s.mat[i,])
}
ests1.mean <- apply(s.mat, 1, mean)
identical(ests.mean, ests1.mean)
mat.samps <- function(n, nsim, rx = rnorm, ...) {
samps <- rx(n*nsim, ...)
matrix(sample(samps), nrow=nsim, ncol = n)
}
s.mat <- mat.samps(n = 25, nsim = 10000)
ests.mean <- numeric(10000)
for (i in 1:10000) {
ests.mean[i] <- mean(s.mat[i,])
}
ests1.mean <- apply(s.mat, 1, mean)  # equivalent code
identical(ests.mean, ests1.mean)   # yes identical
ests1.mean
x <- c(0, 1000, 2000)
y <- c(1000, 0 , 1000)
plot(x, y, pch = "", xlab = "Estimate", ylab = "Loss")
lines(x,y)
x <- 1:6
y <- c(1,1,0,1,1,1)
plot(x, y, pch = 19, xlab = "Estimate", ylab = "Loss")
library(devtools)
install_github("mdedge/stfspack")
library(stfspack)
rnorm.contam(n=100,nsim=1000)
rnorm.contam()
str(rnorm.contam())
?rnorm.contam()
rnorm.contam(n=100, mu = 0, sigma = 1, contam.p = 0.01, contam.mu = -5,
contam.sigma = 0)
rnorm.mix(20, 0, 1, .2, 10, 1)
rnorm.contam(20, 0, 1, .2, 10, 1)
rnorm.contam(20, 0, 1, .2, 10, 1)
counter <‐ 0                 # set counter to 0
t.crit <‐ qt(0.975,14)   #5% critical value
for (i in 1:1000)
{
x <‐ rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <‐ (mean(x)‐25)*sqrt(15)/sd(x)
if (t >= t.crit)        # check to see if result is significant
counter <‐ counter + 1       # increase counter by 1
}
counter/1000  #compute estimate of Type I error rate
counter <‐ 0                 # set counter to 0
t.crit <‐ qt(0.975,14)   #5% critical value
for (i in 1:1000)
{
x <‐ rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <‐ (mean(x)‐25)*sqrt(15)/sd(x)
if (t >= t.crit)        # check to see if result is significant
counter <‐ counter + 1       # increase counter by 1
}
counter/1000  #compute estimate of Type I error rate
counter <‐ 0                 # set counter to 0
t.crit <‐ qt(0.975,14)   #5% critical value
for (i in 1:1000)
{
x <‐ rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <‐ (mean(x)‐25)*sqrt(15)/sd(x)
if (t >= t.crit)        # check to see if result is significant
counter <‐ counter + 1       # increase counter by 1
}
counter/1000  #compute estimate of Type I error rate
counter <‐ 0                 # set counter to 0
t.crit <‐ qt(0.975,14)   #5% critical value
for (i in 1:1000)
{
x <‐ rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <‐ (mean(x)‐25)*sqrt(15)/sd(x)
if (t >= t.crit)        # check to see if result is significant
counter <‐ counter + 1       # increase counter by 1
}
counter/1000  #compute estimate of Type I error rate
counter <‐ 0                 # set counter to 0
t.crit <‐ qt(0.975,14)   #5% critical value
for (i in 1:1000)
{
x <‐ rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <‐ (mean(x)‐25)*sqrt(15)/sd(x)
if (t >= t.crit)        # check to see if result is significant
counter <‐ counter + 1       # increase counter by 1
}
counter/1000  #compute estimate of Type I error rate
counter <‐ 0                 # set counter to 0
t.crit <‐ qt(0.975,14)   #5% critical value
for (i in 1:1000)
{
x <‐ rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <‐ (mean(x)‐25)*sqrt(15)/sd(x)
if (t >= t.crit)        # check to see if result is significant
counter <‐ counter + 1       # increase counter by 1
}
counter/1000  #compute estimate of Type I error rate
counter <‐ 0                 # set counter to 0
t.crit <‐ qt(0.975,14)   #5% critical value
for (i in 1:1000)
{
x <‐ rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <‐ (mean(x)‐25)*sqrt(15)/sd(x)
if (t >= t.crit)        # check to see if result is significant
counter <‐ counter + 1       # increase counter by 1
}
counter/1000  #compute estimate of Type I error rate
counter <‐ 0                 # set counter to 0
t.crit <‐ qt(0.975,14)   #5% critical value
for (i in 1:1000)
{
x <‐ rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <‐ (mean(x)‐25)*sqrt(15)/sd(x)
if (t >= t.crit)        # check to see if result is significant
counter <‐ counter + 1       # increase counter by 1
}
counter/1000  #compute estimate of Type I error rate
counter <‐ 0                 # set counter to 0
t.crit <‐ qt(0.975,14)   #5% critical value
for (i in 1:1000)
{
x <‐ rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <‐ (mean(x)‐25)*sqrt(15)/sd(x)
if (t >= t.crit)        # check to see if result is significant
counter <‐ counter + 1       # increase counter by 1
}
counter/1000  #compute estimate of Type I error rate
counter <‐ 0                 # set counter to 0
t.crit <‐ qt(0.975,14)   #5% critical value
for (i in 1:1000)
{
x <‐ rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <‐ (mean(x)‐25)*sqrt(15)/sd(x)
if (t >= t.crit)        # check to see if result is significant
counter <‐ counter + 1       # increase counter by 1
}
counter/1000  #compute estimate of Type I error rate
counter <‐ 0                 # set counter to 0
t.crit <‐ qt(0.975,14)   #5% critical value
for (i in 1:1000)
{
x <‐ rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <‐ (mean(x)‐25)*sqrt(15)/sd(x)
if (abs(t) >= t.crit)        # check to see if result is significant
counter <‐ counter + 1       # increase counter by 1
}
counter/1000  #compute estimate of Type I error rate
counter <‐ 0                 # set counter to 0
t.crit <‐ qt(0.975,14)   #5% critical value
for (i in 1:1000)
{
x <‐ rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <‐ (mean(x)‐25)*sqrt(15)/sd(x)
if (abs(t) >= t.crit)        # check to see if result is significant
counter <‐ counter + 1       # increase counter by 1
}
counter/1000  #compute estimate of Type I error rate
counter <‐ 0                 # set counter to 0
t.crit <‐ qt(0.975,14)   #5% critical value
for (i in 1:1000)
{
x <‐ rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <‐ (mean(x)‐25)*sqrt(15)/sd(x)
if (abs(t) >= t.crit)        # check to see if result is significant
counter <‐ counter + 1       # increase counter by 1
}
counter/1000  #compute estimate of Type I error rate
counter <‐ 0                 # set counter to 0
t.crit <‐ qt(0.975,14)   #5% critical value
for (i in 1:1000)
{
x <‐ rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <‐ (mean(x)‐25)*sqrt(15)/sd(x)
if (abs(t) >= t.crit)        # check to see if result is significant
counter <‐ counter + 1       # increase counter by 1
}
counter/1000  #compute estimate of Type I error rate
counter <‐ 0                 # set counter to 0
t.crit <‐ qt(0.975,14)   #5% critical value
for (i in 1:1000)
{
x <‐ rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <‐ (mean(x)‐25)*sqrt(15)/sd(x)
if (abs(t) >= t.crit)        # check to see if result is significant
counter <‐ counter + 1       # increase counter by 1
}
counter/1000  #compute estimate of Type I error rate
counter <‐ 0                 # set counter to 0
t.crit <‐ qt(0.975,14)   #5% critical value
for (i in 1:1000)
{
x <‐ rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <‐ (mean(x)‐25)*sqrt(15)/sd(x)
if (abs(t) >= t.crit)        # check to see if result is significant
counter <‐ counter + 1       # increase counter by 1
}
counter/1000  #compute estimate of Type I error rate
counter <-  0                 # set counter to 0
t.crit <- qt(0.975, 14)   #5% critical value for 2 tailed test for N = 15, df = 14
for (i in 1:1000)
{
x <- rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <- (mean(x) - 25) * sqrt(15) / sd(x)  # do a t test
if (abs(t) >= t.crit)        # check to see if result is significant
counter <- counter + 1       # increase counter by 1
}
counter/1000  #compute estimate of Type I error rate
counter <-  0                 # set counter to 0
t.crit <- qt(0.975, 14)   #5% critical value for 2 tailed test for N = 15, df = 14
for (i in 1:1000)
{
x <- rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <- (mean(x) - 25) * sqrt(15) / sd(x)  # do a t test
if (abs(t) >= t.crit)        # check to see if result is significant
counter <- counter + 1       # increase counter by 1
}
counter/1000  #compute estimate of Type I error rate
rnorm(15, 25, 4)
counter <-  0
for (i in 1:1000)
{
x <- rnorm(15, 25, 4)
t <- (mean(x) - 25) * sqrt(15) / sd(x)
if (abs(t) >= t.crit)
counter <- counter + 1
}
counter/1000
counter <-  0
for (i in 1:1000)
{
x <- rnorm(15, 25, 4)
t <- (mean(x) - 25) * sqrt(15) / sd(x)
if (abs(t) >= t.crit)
counter <- counter + 1
}
counter/1000
set.seed(1234)   # to obtain the same sampling result
counter <-  0                 # set counter to 0
t.crit <- qt(0.975, 14)   #5% critical value for 2 tailed test for N = 15, df = 14
for (i in 1:1000)
{
x <- rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <- (mean(x) - 25) * sqrt(15) / sd(x)  # do a t test
if (abs(t) >= t.crit)        # check to see if result is significant
counter <- counter + 1       # increase counter by 1
}
counter/1000  # compute estimate of Type I error rate
set.seed(123)   # to obtain the same sampling result
counter <-  0                 # set counter to 0
t.crit <- qt(0.975, 14)   #5% critical value for 2 tailed test for N = 15, df = 14
for (i in 1:1000)
{
x <- rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <- (mean(x) - 25) * sqrt(15) / sd(x)  # do a t test
if (abs(t) >= t.crit)        # check to see if result is significant
counter <- counter + 1       # increase counter by 1
}
counter/1000  # compute estimate of Type I error rate
counter <-  0                 # set counter to 0
t.crit <- qt(0.975, 14)   #5% critical value for 2 tailed test for N = 15, df = 14
for (i in 1:1000)
{
x <- rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <- (mean(x) - 25) * sqrt(15) / sd(x)  # do a t test
if (abs(t) >= t.crit)        # check to see if result is significant
counter <- counter + 1       # increase counter by 1
}
counter/1000  # compute estimate of Type I error rate
counter <-  0                 # set counter to 0
t.crit <- qt(0.975, 14)   #5% critical value for 2 tailed test for N = 15, df = 14
for (i in 1:1000)
{
x <- rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <- (mean(x) - 25) * sqrt(15) / sd(x)  # do a t test
if (abs(t) >= t.crit)        # check to see if result is significant
counter <- counter + 1       # increase counter by 1
}
counter/1000  # compute estimate of Type I error rate
set.seed(1234)   # to obtain the same sampling result
counter <-  0                 # set counter to 0
t.crit <- qt(0.975, 14)   #5% critical value for 2 tailed test for N = 15, df = 14
for (i in 1:1000)
{
x <- rnorm(15, 25, 4)         # draw a random sample of size 15 from a N(25,4) distribution
t <- (mean(x) - 25) * sqrt(15) / sd(x)  # do a t test
if (abs(t) >= t.crit)        # check to see if result is significant
counter <- counter + 1       # increase counter by 1
}
counter/1000  # compute estimate of Type I error rate
set.seed(1234)
nsims <- 1000
t.crit <- qt(0.975,14)           #5% critical value
results <- numeric(nsims)       #Vector to store t statistics
for (i in 1:nsims)
{
x <- rnorm(15, mean=0, sd=1)  # draw a random sample of size 15 from a N(25,4) distribution
results[i] <- (mean(x) - 0)*sqrt(15)/sd(x)
}
sum(abs(results) >= t.crit)/nsims    #compute estimate of error rate
results
x[2]
x <- rnorm(15, 25, 4)
x
x[2]
set.seed(1234)
nsims <- 1000
t.crit <- qt(0.975,14)           #5% critical value
results <- numeric(nsims)       #Vector to store t statistics
for (i in 1:nsims)
{
x <- rnorm(15, mean=0, sd=1)  # draw a random sample of size 15 from a N(25,4) distribution
results[i] <- (mean(x) - 0)*sqrt(15)/sd(x)
}
sum(abs(results) >= t.crit)/nsims    #compute estimate of error rate
hist(results, freq = F, ylim=c(0,0.4))    # Plot histogram of t
curve(dt(x,14), add = TRUE)       # superimpose t(14) density
hist(x)
hist(results, freq = F, ylim=c(0,0.4))    # Plot histogram of t statistics
curve(dt(x,14), add = TRUE)       # superimpose t(14) density
hist(results, freq = F, ylim=c(0,0.4))    # Plot histogram of t statistics
curve(dt(z,14), add = TRUE)       # superimpose t(14) density
?hist
library(curl)
library(readODS)
install.packages("readODS")
ukhsa_fig33_tbl <- read_ods(temp, sheet = “Figure_33&34__Primary_care”,
range = ukhsa_fig33_range) %>%
janitor::clean_names() %>%
as_tibble() %>%
dplyr::mutate(week_end_date = seq(ukhsa_2021_w_end_date,
ukhsa_2022_w_end_date, by = “7 days”)) %>%
filter(week_end_date != ukhsa_2021_w_end_date)
temp <- tempfile()
ukhsa_flucovid_df <- dplyr::full_join(ukhsa_fig33_tbl, ukhsa_fig39_tbl, by = “week_number”) %>%
dplyr::filter(week_end_date >= ukhsa_analysis_date) %>% dplyr::left_join(phe_rcgp_tbl,
by = “week_number”) %>% dplyr::select(week_number, week_end_date, covid_19_like_indicator_rate,
ili_rate, ili_rate_2018_19, covid_19_hospital_admission_rate, influenza_hospital_admission_rate) %>%
tidyr::pivot_longer(cols = 3:7, names_to = “measures”, values_to = “rates”) %>% tidyr::drop_na()
library(dplyr)
ukhsa_fig33_tbl <- read_ods(temp, sheet = “Figure_33&34__Primary_care”,
range = ukhsa_fig33_range) %>%
janitor::clean_names() %>%
as_tibble() %>%
dplyr::mutate(week_end_date = seq(ukhsa_2021_w_end_date,
ukhsa_2022_w_end_date, by = “7 days”)) %>%
filter(week_end_date != ukhsa_2021_w_end_date)
ukhsa_fig33_tbl <- read_ods(temp, sheet = “Figure_33&34__Primary_care”,
range = ukhsa_fig33_range) %>%
janitor::clean_names() %>%
as_tibble() %>%
dplyr::mutate(week_end_date = seq(ukhsa_2021_w_end_date,
ukhsa_2022_w_end_date, by = “7 days”)) %>%
filter(week_end_date != ukhsa_2021_w_end_date)
ukhsa_fig33_tbl <- read_ods(temp, sheet = "Figure_33&34__Primary_care",
range = ukhsa_fig33_range) %>%
janitor::clean_names() %>%
as_tibble() %>%
dplyr::mutate(week_end_date = seq(ukhsa_2021_w_end_date,
ukhsa_2022_w_end_date, by = "7 days")) %>%
filter(week_end_date != ukhsa_2021_w_end_date)
install.packages("janitor")
library(janitor)
ukhsa_fig33_tbl <- read_ods(temp, sheet = "Figure_33&34__Primary_care",
range = ukhsa_fig33_range) %>%
janitor::clean_names() %>%
as_tibble() %>%
dplyr::mutate(week_end_date = seq(ukhsa_2021_w_end_date,
ukhsa_2022_w_end_date, by = "7 days")) %>%
filter(week_end_date != ukhsa_2021_w_end_date)
library(readODS)
ukhsa_fig33_tbl <- read_ods(temp, sheet = "Figure_33&34__Primary_care",
range = ukhsa_fig33_range) %>%
janitor::clean_names() %>%
as_tibble() %>%
dplyr::mutate(week_end_date = seq(ukhsa_2021_w_end_date,
ukhsa_2022_w_end_date, by = "7 days")) %>%
filter(week_end_date != ukhsa_2021_w_end_date)
## Packages and Themes
library(tidyverse)
install.packages("tidyverse")
## Packages and Themes
library(tidyverse)
library(curl)
library(readODS)
library(lubridate)
library(scales)
library(patchwork)
install.packages("patchwork")
library(patchwork)
# Next, we load the plotting theme
source("/cloud/project/code/00-UPD/CBN Theme.R")
## Drawing the data
# We draw the data from the online weekly flu and Covid-19 report file
ukhsa_url <- "https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1057083/Weekly_Influenza_and_COVID19_report_data_w8.ods"
ukhsa_2021_w_end_date <- as_date("2021-02-21")
ukhsa_2022_w_end_date <- as_date("2022-02-20")
ukhsa_analysis_date <- as_date("2021-07-04")
ukhsa_fig33_range <- "B8:E61"
ukhsa_fig39_range <- "B8:D60"
library(jmv)        # this has all of jamovi's analyses to run in R
library(pacman)
library(jmvtools)  # for the development of modules
library(jmvcore)
install.packages('jmvtools', repos=c('https://repo.jamovi.org', 'https://cran.r-project.org'))
install.packages('Rtools', repos='https://cran.rstudio.com/bin/windows/Rtools/')
install.packages("pacman")
# install.packages('Rtools', repos='https://cran.rstudio.com/bin/windows/Rtools/')
install.packages('jmvtools', repos=c('https://repo.jamovi.org', 'https://cran.r-project.org'))
install.packages("jmv")
library(jmv)        # this has all of jamovi's analyses to run in R
install.packages("devtools")
library(jevaex1)
?l2sttest
?l2sttest
data('ToothGrowth')
jevaex1::l2sttest(
data = data,
dep = len,
group = supp)
ToothGrowth
data <- ToothGrowth
jevaex1::l2sttest(
data = data,
dep = len,
group = supp)
data('ToothGrowth')
jevaex1::l2sttest(data = ToothGrowth, dep = len, group = supp)
jevaex1::l2sttest
jevaex1::?l2sttest
?jevaex1::l2sttest
library(jeva)
?mcnem()
library(jmvcore)
library(jmvtools)  # for the development of modules
library(jmv)        # this has all of jamovi's analyses to run in R
library(pacman)
library(devtools)
library(node)
jmvtools::check(home='C:\\Program Files\\jamovi 2.3.17.0')
options(jamovi_home='C:\\Program Files\\jamovi 2.3.17.0')
setwd("C:/Users/peteq/Dropbox/Working/Masters/Biostatistics/statistics/Likelihood/jam_dir")
setwd('jeva')
data('mtcars')
jeva::lcorr(data = mtcars, depa = mpg, depb = cyl)
p_unlock(lib.loc = "C:/Users/peteq/Dropbox/Working/Masters/Biostatistics/statistics/Likelihood/jam_dir/jeva/build/R4.1.2-win64/")
jmvtools::install()
p_unlock(lib.loc = "C:/Users/peteq/Dropbox/Working/Masters/Biostatistics/statistics/Likelihood/jam_dir/jeva/build/R4.1.2-win64/")
jmvtools::install()
p_unlock(lib.loc = "C:/Users/peteq/Dropbox/Working/Masters/Biostatistics/statistics/Likelihood/jam_dir/jeva/build/R4.1.2-win64/")
jmvtools::install()
p_unlock(lib.loc = "C:/Users/peteq/Dropbox/Working/Masters/Biostatistics/statistics/Likelihood/jam_dir/jeva/build/R4.1.2-win64/")
jmvtools::install()
p_unlock(lib.loc = "C:/Users/peteq/Dropbox/Working/Masters/Biostatistics/statistics/Likelihood/jam_dir/jeva/build/R4.1.2-win64/")
jmvtools::install()
